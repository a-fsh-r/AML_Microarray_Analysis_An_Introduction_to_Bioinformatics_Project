{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afsharp/Bioinformatics_Microarray_Analysis/blob/main/lungCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QjRGHMvwGOJc"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#col_list = [\"GENDER\", \"AGE\",\"SMOKING\", 'YELLOW_FINGERS','ANXIETY', 'PEER_PRESSURE','CHRONIC DISEASE',\t'FATIGUE',\t'ALLERGY',\t'WHEEZING',\t'ALCOHOL CONSUMING'\t,'COUGHING',\t'SHORTNESS OF BREATH'\t,'SWALLOWING DIFFICULTY',\t'CHEST PAIN']\n",
        "data = pd.read_csv(\"/content/lungcancer (1).csv\")\n",
        "data1 = data.copy()\n",
        "target = data['LUNG_CANCER']\n",
        "features = data\n",
        "data.pop('LUNG_CANCER')\n",
        "#features"
      ],
      "metadata": {
        "id": "UG3Erke7GaOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train-test split code**"
      ],
      "metadata": {
        "id": "OcbIAfWfpqro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_split = data1.sample(frac=1)\n",
        "\n",
        "train_size = 0.5\n",
        "train_end = int(len(data_split)*train_size)\n",
        "\n",
        "data_train = data_split[:train_end]\n",
        "data_test = data_split[train_end:]\n",
        "\n",
        "data_train"
      ],
      "metadata": {
        "id": "Kew7dHteoX4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Calculating the entropy of the whole dataset**"
      ],
      "metadata": {
        "id": "cQyn9ehxMNv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def total_entropy(train, label, class_list):\n",
        "    total_row = train.shape[0]\n",
        "    total_entr = 0\n",
        "    \n",
        "    for i in class_list:\n",
        "        total = train[train[label] == i].shape[0]\n",
        "        total_entr = - (total/total_row)*np.log2(total/total_row) \n",
        "        total_entr += total_entr\n",
        "    \n",
        "    return total_entr"
      ],
      "metadata": {
        "id": "kkQ9cvI3K62Y"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating the entropy for the filtered dataset**"
      ],
      "metadata": {
        "id": "kJTZi0K2MRmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_entropy(features, label, class_list):\n",
        "    class_count = features.shape[0]\n",
        "    entropy = 0\n",
        "    \n",
        "    for i in class_list:\n",
        "        label_class_count = features[features[label] == i].shape[0]  \n",
        "        entropy_class = 0\n",
        "        if label_class_count != 0:\n",
        "            probability_class = label_class_count/class_count  \n",
        "            entropy_class = - probability_class * np.log2(probability_class)  \n",
        "        entropy += entropy_class\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "omPvVzhBMVl2"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating information gain for a feature**"
      ],
      "metadata": {
        "id": "JNTISyGWMgzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_gain(feature_name, train_data, label, class_list):\n",
        "    feature_value_list = train_data[feature_name].unique()\n",
        "    total_row = train_data.shape[0]\n",
        "    feature_info = 0.0\n",
        "    \n",
        "    for feature_value in feature_value_list:\n",
        "        feature_value_data = train_data[train_data[feature_name] == feature_value]  \n",
        "        feature_value_count = feature_value_data.shape[0]\n",
        "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list)  \n",
        "        feature_value_probability = feature_value_count/total_row\n",
        "        feature_info += feature_value_probability * feature_value_entropy  \n",
        "        \n",
        "    return total_entropy(train_data, label, class_list) - feature_info "
      ],
      "metadata": {
        "id": "7f0zkcf6MhrI"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding feature with highest information gain**"
      ],
      "metadata": {
        "id": "9jHtwonWMovA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_highest_information_gaine(train_data, label, class_list):\n",
        "    feature_list = train_data.columns.drop(label)\n",
        "    max_info_gain = -1\n",
        "    max_info_feature = None\n",
        "    \n",
        "    for feature in feature_list: \n",
        "        feature_info_gain = calc_gain(feature, train_data, label, class_list)\n",
        "        if max_info_gain < feature_info_gain:  \n",
        "            max_info_gain = feature_info_gain\n",
        "            max_info_feature = feature\n",
        "            \n",
        "    return max_info_feature"
      ],
      "metadata": {
        "id": "MGjwOy7yMrv7"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding a node to the tree**"
      ],
      "metadata": {
        "id": "ryMIaN9nMwmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
        "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) \n",
        "    tree = {}  \n",
        "    \n",
        "    for feature_value, count in feature_value_count_dict.iteritems():\n",
        "        feature_value_data = train_data[train_data[feature_name] == feature_value]  \n",
        "        assigned_to_node = False  \n",
        "        for c in class_list:  \n",
        "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] \n",
        "\n",
        "            if class_count == count: \n",
        "                tree[feature_value] = c \n",
        "                train_data = train_data[train_data[feature_name] != feature_value] \n",
        "                assigned_to_node = True\n",
        "        if not assigned_to_node:  \n",
        "            tree[feature_value] = \"?\"  \n",
        "            \n",
        "    return tree, train_data"
      ],
      "metadata": {
        "id": "OXq_OgE8MxWL"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing ID3 Algorithm and generating Tree**"
      ],
      "metadata": {
        "id": "k1XZCSSwM3ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
        "    if train_data.shape[0] != 0:\n",
        "        max_info_feature = find_highest_information_gaine(train_data, label, class_list) \n",
        "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list) \n",
        "        next_root = None\n",
        "        \n",
        "        if prev_feature_value != None:\n",
        "            root[prev_feature_value] = dict()\n",
        "            root[prev_feature_value][max_info_feature] = tree\n",
        "            next_root = root[prev_feature_value][max_info_feature]\n",
        "        else:\n",
        "            root[max_info_feature] = tree\n",
        "            next_root = root[max_info_feature]\n",
        "        \n",
        "        for node, branch in list(next_root.items()):\n",
        "            if branch == \"?\":\n",
        "                feature_value_data = train_data[train_data[max_info_feature] == node]\n",
        "                make_tree(next_root, node, feature_value_data, label, class_list) "
      ],
      "metadata": {
        "id": "bBgg0fJLM4UI"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding unique classes of the label and Starting the algorithm**"
      ],
      "metadata": {
        "id": "VpCVHr4qM9iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def id3(train_data, label):\n",
        "    train_data = train_data.copy() \n",
        "    tree = {} \n",
        "    class_list = train_data[label].unique() \n",
        "    make_tree(tree, None, train_data, label, class_list) \n",
        "    return tree"
      ],
      "metadata": {
        "id": "VM3R0RlKM_0T"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = id3(data_train, 'LUNG_CANCER')\n",
        "print(tree)"
      ],
      "metadata": {
        "id": "u8etib2hNDXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = id3(data_test, 'LUNG_CANCER')\n",
        "print(tree)"
      ],
      "metadata": {
        "id": "95A5kYSIaNU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}